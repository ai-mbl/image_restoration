{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Train Probabilistic Noise2Void\n",
    "\n",
    "Probabilistic Noise2Void, just as N2V, allows training from single noisy images.\n",
    "\n",
    "In order to get some additional quality squeezed out of your noisy input data, PN2V employs an additional noise model which can either be measured directly at your microscope or approximated by a process called ‘bootstrapping’.\n",
    "Below we will give you a noise model for the first network to train and then bootstrap one, so you can apply PN2V to your own data if you'd like.\n",
    "\n",
    "Note: The PN2V implementation is written in pytorch, not Keras/TF.  \n",
    "Note: PN2V experienced multiple updates regarding noise model representations. Hence, the [original PN2V repository](https://github.com/juglab/pn2v) is not any more the one we suggest to use (despite it of course working just as described in the original publication). So here we use the [PPN2V repo](https://github.com/juglab/PPN2V) which you cloned during setup.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\") \n",
    "from torch.distributions import normal\n",
    "import matplotlib.pyplot as plt, numpy as np, pickle\n",
    "from scipy.stats import norm\n",
    "from tifffile import imread\n",
    "import sys\n",
    "import os\n",
    "import urllib\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_ppn2v_repo = \"PPN2V\"\n",
    "assert os.path.exists(path_to_ppn2v_repo), \"change the `path_to_ppn2v_repo` to point to the PPN2V repo you cloned during setup\"\n",
    "sys.path.append(path_to_ppn2v_repo)\n",
    "import unet.model\n",
    "from unet.model import UNet\n",
    "from pn2v import *\n",
    "import pn2v.gaussianMixtureNoiseModel\n",
    "import pn2v.histNoiseModel\n",
    "import pn2v.prediction\n",
    "import pn2v.training\n",
    "from pn2v.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation\n",
    "\n",
    "Here we use a dataset of 2D images of fluorescently labeled membranes of Convallaria (lilly of the valley) acquired with a spinning disk microscope. \n",
    "All 100 recorded images (1024×1024 pixels) show the same region of interest and only differ in their noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "zipPath=\"data/Convallaria_diaphragm.zip\"\n",
    "if not os.path.exists(zipPath):  \n",
    "    data = urllib.request.urlretrieve('https://zenodo.org/record/5156913/files/Convallaria_diaphragm.zip?download=1', zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/Convallaria_diaphragm/\"\n",
    "data_name = \"convallaria\" # Name of the noise model \n",
    "calibration_fn = \"20190726_tl_50um_500msec_wf_130EM_FD.tif\"\n",
    "noisy_fn = \"20190520_tl_25um_50msec_05pc_488_130EM_Conv.tif\"\n",
    "noisy_imgs = imread(path+noisy_fn)\n",
    "calibration_imgs = imread(path+calibration_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has a total of four options to generate a noise model for PN2V. You can pick which one you would like to use (and ignore the tasks in the options you don't wanna use)! \n",
    "\n",
    "There are two types of noise models for PN2V: creating a histogram of the noisy pixels based on the averaged GT or using a gaussian mixture model (GMM).\n",
    "For both we need to provide a clean signal as groundtruth. For the dataset we have here we have calibration data available so \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gaussian = 3 # Number of gaussians to use for Gaussian Mixture Model\n",
    "n_coeff = 2 # No. of polynomial coefficients for parameterizing the mean, standard deviation and weight of Gaussian components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Generate a Noise Model using Calibration Data \n",
    "The noise model is a characteristic of your camera. The downloaded data folder contains a set of calibration images (For the Convallaria dataset, it is ```20190726_tl_50um_500msec_wf_130EM_FD.tif``` and the data to be denoised is named ```20190520_tl_25um_50msec_05pc_488_130EM_Conv.tif```). We can either bin the noisy - GT pairs (obtained from noisy calibration images) as a 2-D histogram or fit a GMM distribution to obtain a smooth, parametric description of the noise model.\n",
    "\n",
    "We will use pairs of noisy calibration observations $x_i$ and clean signal $s_i$ (created by averaging these noisy, calibration images) to estimate the conditional distribution $p(x_i|s_i)$. Histogram-based and Gaussian Mixture Model-based noise models are generated and saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_hist_noise_model_cal = '_'.join(['HistNoiseModel', data_name,'calibration'])\n",
    "name_gmm_noise_model_cal = '_'.join(['GMMNoiseModel',data_name,str(n_gaussian),str(n_coeff),'calibration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 4.1</h4>\n",
    "    <p>\n",
    "\n",
    "The calibration data contains 100 images of a static sample. Estimate the clean signal by averaging all the images. \n",
    "Visualize how the raw data compares to the pseudo ground truth signal.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO###\n",
    "# # Average the images in the `observation` array\n",
    "# signal_cal = #TODO\n",
    "\n",
    "# #Visualize a single image from the observation array alongside the average\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the images in the `observation` array\n",
    "signal_cal=np.mean(calibration_imgs[:, ...],axis=0)[np.newaxis,...]\n",
    "\n",
    "#Visualize a single image from the observation array alongside the average\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(label='average (ground truth)')\n",
    "plt.imshow(signal_cal[0],cmap='gray')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(label='single raw image')\n",
    "plt.imshow(calibration_imgs[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The subsequent code expects the signal array to have a dimension for the samples\n",
    "if signal_cal.shape == calibration_imgs.shape[1:]:\n",
    "    signal_cal = signal_cal[np.newaxis,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways of generating a noise model for PN2V: creating a histogram of the noisy pixels based on the averaged GT or using a gaussian mixture model (GMM). You can pick which one you wanna use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;\">\n",
    "\n",
    "### Creating the Histogram Noise Model\n",
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a histogram based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 4.2</h4>\n",
    "    <p>\n",
    "        Look at the docstring for <tt>createHistogram</tt> and use it to create a histogram based on the calibration data using the clean signal you created by averaging as groundtruth.    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pn2v.histNoiseModel.createHistogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO###\n",
    "## Define the parameters for the histogram creation\n",
    "#bins = 256\n",
    "## Values falling outside the range [min_val, max_val] are not included in the histogram, so the values in the images you want to denoise should fall within that range\n",
    "#min_val = #TODO\n",
    "#max_val = #TODO\n",
    "## Create the histogram\n",
    "#histogram_cal = pn2v.histNoiseModel.createHistogram(bins,#TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the histogram creation\n",
    "bins = 256\n",
    "# Values falling outside the range [min_val, max_val] are not included in the histogram, so the values in the images you want to denoise should fall within that range\n",
    "min_val = 234#np.min(noisy_imgs)\n",
    "max_val = 7402#np.max(noisy_imgs)\n",
    "print(\"min:\", min_val,\", max:\", max_val)\n",
    "# Create the histogram\n",
    "histogram_cal = pn2v.histNoiseModel.createHistogram(bins, min_val, max_val, calibration_imgs, signal_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving histogram to disk.\n",
    "np.save(path+name_hist_noise_model_cal+'.npy', histogram_cal)\n",
    "histogramFD_cal=histogram_cal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the histogram-based noise model.\n",
    "plt.xlabel('Observation Bin')\n",
    "plt.ylabel('Signal Bin')\n",
    "plt.imshow(histogramFD_cal**0.25, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;\">\n",
    "\n",
    "### Creating the GMM noise model\n",
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a GMM based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_signal=np.min(signal_cal)\n",
    "max_signal=np.max(signal_cal)\n",
    "print(\"Minimum Signal Intensity is\", min_signal)\n",
    "print(\"Maximum Signal Intensity is\", max_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating the noise model training for `n_epoch=2000` and `batchSize=250000` works the best for `Convallaria` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pn2v.gaussianMixtureNoiseModel.GaussianMixtureNoiseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_noise_model_cal = pn2v.gaussianMixtureNoiseModel.GaussianMixtureNoiseModel(min_signal = min_signal, max_signal =max_signal, path=path, weight = None, n_gaussian = n_gaussian, n_coeff = n_coeff, min_sigma = 50, device = device)\n",
    "gmm_noise_model_cal.train(signal_cal, calibration_imgs, batchSize = 250000, n_epochs = 2000, learning_rate=0.1, name = name_gmm_noise_model_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;\">\n",
    "\n",
    "### Visualizing the Histogram-based and GMM-based noise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only works if you generated both a histogram and GMM-based noise model\n",
    "plotProbabilityDistribution(signalBinIndex=170, histogram=histogramFD_cal, gaussianMixtureNoiseModel=gmm_noise_model_cal, min_signal=min_val, max_signal=max_val, n_bin= bins, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Generate a Noise Model by Bootstrapping\n",
    "Here we bootstrap a suitable histogram noise model and a GMM noise model after denoising the noisy images with Noise2Void and then using these denoised images as pseudo GT. \n",
    "So first, we need to train a N2V model (now with pytorch) to estimate the conditional distribution $p(x_i|s_i)$. No additional calibration data is used for bootstrapping (so no need to use `calibration_imgs` or `singal_cal` again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=data_name +'_n2v'\n",
    "name_hist_noise_model_bootstrap = '_'.join(['HistNoiseModel',data_name, 'bootstrap'])\n",
    "name_gmm_noise_model_bootstrap = '_'.join(['GMMNoiseModel',data_name, str(n_gaussian), str(n_coeff), 'bootstrap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Noise2Void network \n",
    "n2v_net = UNet(1, depth=3)\n",
    "# Prepare training+validation data\n",
    "\n",
    "train_data=noisy_imgs[:-5].copy()\n",
    "val_data=noisy_imgs[-5:].copy()\n",
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history, val_history = pn2v.training.trainNetwork(net=n2v_net, trainData=train_data, valData=val_data,\n",
    "                                           postfix= model_name, directory=path, noiseModel=None,\n",
    "                                           device=device, numOfEpochs= 200, stepsPerEpoch = 10, \n",
    "                                           virtualBatchSize=20, batchSize=1, learningRate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the training and validation loss\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(val_history, label='validation loss')\n",
    "plt.plot(train_history, label='training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now run the N2V model to create pseudo groundtruth.\n",
    "n2v_result_imgs=[]\n",
    "n2v_input_imgs=[]\n",
    "\n",
    "for index in range(noisy_imgs.shape[0]):\n",
    "\n",
    "    im=noisy_imgs[index]\n",
    "    # We are using tiling to fit the image into memory\n",
    "    # If you get an error try a smaller patch size (ps)\n",
    "    n2v_pred = pn2v.prediction.tiledPredict(im, n2v_net, ps=256, overlap=48,\n",
    "                                            device=device, noiseModel=None)\n",
    "    n2v_result_imgs.append(n2v_pred)\n",
    "    n2v_input_imgs.append(im)\n",
    "    if index%10 == 0:\n",
    "        print (\"image:\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In bootstrap mode, we estimate pseudo GT by using N2V denoised images.\n",
    "signal_bootstrap = np.array(n2v_result_imgs)   \n",
    "# Let's look the raw data and our pseudo ground truth signal\n",
    "print(signal_bootstrap.shape)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(label='pseudo GT (generated by N2V denoising)')\n",
    "plt.imshow(signal_bootstrap[0],cmap='gray')\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(signal_bootstrap[0,-128:,-128:],cmap='gray')\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(label='single raw image')\n",
    "plt.imshow(noisy_imgs[0],cmap='gray')\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(noisy_imgs[0,-128:,-128:], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have pseudoGT, you can pick again between a histogram based noise model and a GMM noise model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;\">\n",
    "\n",
    "### Creating the Histogram Noise Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 4.3</h4>\n",
    "    <p>\n",
    "    If you've already done Task 4.2, this is very similar!\n",
    "        Look at the docstring for <tt>createHistogram</tt> and use it to create a histogram using the bootstraped signal you created from the N2V predictions.    \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pn2v.histNoiseModel.createHistogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO###\n",
    "## Define the parameters for the histogram creation\n",
    "#bins = 256\n",
    "## Values falling outside the range [min_val, max_val] are not included in the histogram, so the values in the images you want to denoise should fall within that range\n",
    "#min_val = #TODO\n",
    "#max_val = #TODO\n",
    "## Create the histogram\n",
    "#histogram_bootstrap = pn2v.histNoiseModel.createHistogram(bins,#TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the histogram creation\n",
    "bins = 256\n",
    "# Values falling outside the range [min_val, max_val] are not included in the histogram, so the values in the images you want to denoise should fall within that range\n",
    "min_val = np.min(noisy_imgs)\n",
    "max_val = np.max(noisy_imgs)\n",
    "# Create the histogram\n",
    "histogram_bootstrap = pn2v.histNoiseModel.createHistogram(bins, min_val, max_val, noisy_imgs, signal_bootstrap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving histogram to disk.\n",
    "np.save(path+name_hist_noise_model_bootstrap+'.npy', histogram_bootstrap)\n",
    "histogramFD_bootstrap=histogram_bootstrap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the histogram-based noise model\n",
    "plt.xlabel('Observation Bin')\n",
    "plt.ylabel('Signal Bin')\n",
    "plt.imshow(histogramFD_bootstrap**0.25, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;\">\n",
    "\n",
    "### Creating the GMM noise model\n",
    "Using the raw pixels $x_i$, and our averaged GT $s_i$, we are now learning a GMM based noise model. It describes the distribution $p(x_i|s_i)$ for each $s_i$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_signal=np.percentile(signal_bootstrap, 0.5)\n",
    "max_signal=np.percentile(signal_bootstrap, 99.5)\n",
    "print(\"Minimum Signal Intensity is\", min_signal)\n",
    "print(\"Maximum Signal Intensity is\", max_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating the noise model training for `n_epoch=2000` and `batchSize=250000` works the best for `Convallaria` dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_noise_model_bootstrap = pn2v.gaussianMixtureNoiseModel.GaussianMixtureNoiseModel(min_signal = min_signal, max_signal = max_signal, path=path, weight = None, n_gaussian = n_gaussian, n_coeff = n_coeff, device = device, min_sigma = 50)\n",
    "gmm_noise_model_bootstrap.train(signal_bootstrap, noisy_imgs, batchSize = 250000, n_epochs = 2000, learning_rate = 0.1, name = name_gmm_noise_model_bootstrap, lowerClip = 0.5, upperClip = 99.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Histogram-based and GMM-based noise models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This only works if you generated both a histogram and GMM-based noise model\n",
    "plotProbabilityDistribution(signalBinIndex=170, histogram=histogramFD_bootstrap, gaussianMixtureNoiseModel=gmm_noise_model_bootstrap, min_signal=min_val, max_signal=max_val, n_bin= bins, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## PN2V Training\n",
    "\n",
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 4.4</h4>\n",
    "    <p>\n",
    "    Adapt to use the noise model of your choice here to then train PN2V with.   \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO###\n",
    "noise_model_type = \"gmm\" # pick: \"hist\" or \"gmm\"\n",
    "noise_model_data = \"bootstrap\" # pick: \"calibration\" or \"bootstrap\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if noise_model_type == \"hist\":\n",
    "    noise_model_name = \"_\".join([\"HistNoiseModel\", data_name, noise_model_data])\n",
    "    histogram = np.load(path+noise_model_name+'.npy') \n",
    "    noise_model= pn2v.histNoiseModel.NoiseModel(histogram, device=device)\n",
    "elif noise_model_type == \"gmm\":\n",
    "    noise_model_name = \"_\".join([\"GMMNoiseModel\", data_name, str(n_gaussian), str(n_coeff), noise_model_data])\n",
    "    params= np.load(path+noise_model_name+'.npz')\n",
    "    noise_model = pn2v.gaussianMixtureNoiseModel.GaussianMixtureNoiseModel(params = params, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a network with 800 output channels that are interpreted as samples from the prior.\n",
    "pn2v_net = UNet(800, depth=3)\n",
    "\n",
    "# Start training.\n",
    "trainHist, valHist = pn2v.training.trainNetwork(net=pn2v_net, trainData=train_data, valData=val_data,\n",
    "                                           postfix=noise_model_name, directory=path, noiseModel=noise_model,\n",
    "                                           device=device, numOfEpochs= 200, stepsPerEpoch=5, \n",
    "                                           virtualBatchSize=20, batchSize=1, learningRate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## PN2V Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=noisy_imgs[:,:512,:512]\n",
    "# We are loading only a sub image to speed up computation\n",
    "\n",
    "# We estimate the ground truth by averaging.\n",
    "test_data_gt=np.mean(test_data[:,...],axis=0)[np.newaxis,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn2v_net=torch.load(path+\"/last_\"+noise_model_name+\".net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are processing data and calculating PSNR values.\n",
    "mmse_psnrs=[]\n",
    "prior_psnrs=[]\n",
    "input_psnrs=[]\n",
    "result_ims=[]\n",
    "input_ims=[]\n",
    "\n",
    "# We iterate over all test images.\n",
    "for index in range(test_data.shape[0]):\n",
    "    \n",
    "    im=test_data[index]\n",
    "    gt=test_data_gt[0] # The ground truth is the same for all images\n",
    "    \n",
    "    # We are using tiling to fit the image into memory\n",
    "    # If you get an error try a smaller patch size (ps)\n",
    "    means, mse_est = pn2v.prediction.tiledPredict(im, pn2v_net ,ps=192, overlap=48,\n",
    "                                            device=device, noiseModel=noise_model)\n",
    "    \n",
    "    result_ims.append(mse_est)\n",
    "    input_ims.append(im)\n",
    "\n",
    "    range_psnr=np.max(gt)-np.min(gt)\n",
    "    psnr=PSNR(gt, mse_est,range_psnr )\n",
    "    psnr_prior=PSNR(gt, means,range_psnr )\n",
    "    input_psnr=PSNR(gt,im,range_psnr)\n",
    "    mmse_psnrs.append(psnr)\n",
    "    prior_psnrs.append(psnr_prior)\n",
    "    input_psnrs.append(input_psnr)\n",
    "\n",
    "    print (\"image:\",index)\n",
    "    print (\"PSNR input\",input_psnr)\n",
    "    print (\"PSNR prior\",psnr_prior) # Without info from masked pixel\n",
    "    print (\"PSNR mse\",psnr) # MMSE estimate using the masked pixel\n",
    "    print ('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pn2v.prediction.tiledPredict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 4.5</h4>\n",
    "    <p>\n",
    "    Add a plot with line plots along horizontal lines.   \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO###\n",
    "\n",
    "# We display the results for the last test image       \n",
    "vmi=np.percentile(gt,0.01)\n",
    "vma=np.percentile(gt,99)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(label='Input Image')\n",
    "plt.imshow(im, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(label='Avg. Prior')\n",
    "plt.imshow(means, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(label='PN2V-MMSE estimate')\n",
    "plt.imshow(mse_est, vmax=vma, vmin=vmi, cmap='magma')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(label='Input Image')\n",
    "plt.imshow(im[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "plt.axhline(y=50, linewidth=3, color='white', alpha=0.5, ls=\"--\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(label='Avg. Prior')\n",
    "plt.imshow(means[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "plt.axhline(y=50, linewidth=3, color='white', alpha=0.5, ls=\"--\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(label='PN2V-MMSE estimate')\n",
    "plt.imshow(mse_est[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "plt.axhline(y=50, linewidth=3, color='white', alpha=0.5, ls=\"--\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "#TODO\n",
    "plt.plot()\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(\"Avg PSNR Prior:\", np.mean(np.array(prior_psnrs) ), '+-(2SEM)',2*np.std(np.array(prior_psnrs) )/np.sqrt(float(len(prior_psnrs)) ) )\n",
    "print(\"Avg PSNR MMSE:\", np.mean(np.array(mmse_psnrs) ),  '+-(2SEM)' ,2*np.std(np.array(mmse_psnrs) )/np.sqrt(float(len(mmse_psnrs)) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display the results for the last test image       \n",
    "vmi=np.percentile(gt,0.01)\n",
    "vma=np.percentile(gt,99)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(label='Input Image')\n",
    "plt.imshow(im, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(label='Avg. Prior')\n",
    "plt.imshow(means, vmax=vma, vmin=vmi, cmap='magma')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(label='PN2V-MMSE estimate')\n",
    "plt.imshow(mse_est, vmax=vma, vmin=vmi, cmap='magma')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(label='Input Image')\n",
    "plt.imshow(im[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "plt.axhline(y=50, linewidth=3, color='white', alpha=0.5, ls=\"--\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(label='Avg. Prior')\n",
    "plt.imshow(means[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "plt.axhline(y=50, linewidth=3, color='white', alpha=0.5, ls=\"--\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(label='PN2V-MMSE estimate')\n",
    "plt.imshow(mse_est[100:200,150:250], vmax=vma, vmin=vmi, cmap='magma')\n",
    "plt.axhline(y=50, linewidth=3, color='white', alpha=0.5, ls=\"--\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(im[150,150:250], label=\"Input Image\")\n",
    "plt.plot(means[150,150:250], label=\"Avg. Prior\")\n",
    "plt.plot(mse_est[150,150:250], label=\"PN2V-MMSE estimate\")\n",
    "plt.plot(gt[150,150:250], label=\"Pseudo GT by averaging\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "print(\"Avg PSNR Prior:\", np.mean(np.array(prior_psnrs) ), '+-(2SEM)',2*np.std(np.array(prior_psnrs) )/np.sqrt(float(len(prior_psnrs)) ) )\n",
    "print(\"Avg PSNR MMSE:\", np.mean(np.array(mmse_psnrs) ),  '+-(2SEM)' ,2*np.std(np.array(mmse_psnrs) )/np.sqrt(float(len(mmse_psnrs)) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 4.6</h4>\n",
    "    <p>\n",
    "    Try PN2V for your own data! You probably don't have calibration data, but with the bootstrapping method you don't need any!  \n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "<div class=\"alert alert-block alert-success\"><h1>\n",
    "    Congratulations!</h1>\n",
    "    <p>\n",
    "    <b>You have reached the bonus checkpoint of this exercise! Please mark your progress on slack!</b>\n",
    "    </p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pn2v]",
   "language": "python",
   "name": "conda-env-pn2v-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
