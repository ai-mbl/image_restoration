{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Train a Noise2Noise network with CARE\n",
    "\n",
    "We will now train a 2D Noise2Noise network using CARE. We will closely follow along the previous example but now you will have to fill in some parts on your own!\n",
    "You will have to make decisions - make them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But first some clean up...\n",
    "\n",
    "Make sure your previous notebook is shutdown to avoid running into GPU out-of-memory problems later.\n",
    "A good way of checking is by clicking on the 'Running'-tab in your main jupyter tab, then on the orange 'Shutdown' button next to the notebooks that are no longer needed.\n",
    "![title](nb_material/notebook_shutdown.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import os\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from tifffile import imread, imwrite\n",
    "from csbdeep.utils import axes_dict, download_and_extract_zip_file, Path, plot_history, plot_some\n",
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "from csbdeep.data import RawData, create_patches\n",
    "from csbdeep.io import load_training_data, save_tiff_imagej_compatible\n",
    "from csbdeep.models import Config, CARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Part 1: Training Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download example data\n",
    "\n",
    "To train a Noise2Noise setup we need several acquisitions of the same sample. \n",
    "The data we're downloading here contains 2 tiff-stacks, one for training and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_and_extract_zip_file (\n",
    "    url       = 'https://download.fht.org/jug/n2n_sem_data/n2n_sem_data.zip',\n",
    "    targetdir = 'data',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data!\n",
    "Each image is a tiff stack containing 7 images of the same tissue recorded with different scan time settings of a Scanning Electron Miscroscope (SEM). The faster a SEM image is scanned, the noisier it gets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = imread('data/SEM/train/train.tif')\n",
    "x_size = imgs.shape\n",
    "print('image size =', x_size)\n",
    "scantimes_all = [\"0.2us\", \"0.5us\", \"1us\", \"1us\", \"2.1us\", \"5us\", \"5us, avg of 4\"]\n",
    "plt.figure(figsize=(40,16))\n",
    "plot_some(imgs,\n",
    "          title_list=[scantimes_all], \n",
    "          pmin=.2,pmax=99.8, cmap=\"gray_r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 2.1:</h4>\n",
    "    <p>\n",
    "    The noise level is hard to see at this zoom level. Let's also look at a smaller crop of them! Play around with this until you have a feeling for what the data looks like.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###TODO###\n",
    "\n",
    "imgs_cropped = #TODO\n",
    "\n",
    "plt.figure(figsize=(40,16))\n",
    "plot_some(imgs_cropped,\n",
    "          title_list=[scantimes_all], \n",
    "          pmin=.2,pmax=99.8, cmap=\"gray_r\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that you didn't crop x_train itself, we still need that!\n",
    "assert imgs.shape == x_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the last image, which is the average of 4 images with 5us scantime, has the highest signal-to-noise-ratio. It is not noise-free but our best choice to be able to compare our results against quantitatively, so we will set it aside for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scantimes, scantime_highSNR = scantimes_all[:-1], scantimes_all[-1]\n",
    "x_train, x_highSNR = imgs[:-1], imgs[-1]\n",
    "print(scantimes, scantime_highSNR)\n",
    "print(x_train.shape, x_highSNR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data for CARE\n",
    "\n",
    "Let's try and train a network to denoise images of $1 \\mu s$ scan time!\n",
    "Which images do you think could be used as input and which as target?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 2.2:</h4>\n",
    "    <p>\n",
    "    Decide which images to use as inputs and which as targets. Then, remember from part one how the data has to be organized to match up inputs and targets.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO###\n",
    "base_path = \"data/SEM/train\"\n",
    "source_dir = os.path.join(base_path, \"\") # pick path in which to save inputs\n",
    "target_dir = os.path.join(base_path, \"\")# pick path in which to save targets\n",
    "os.makedirs(source_dir, exist_ok=True)\n",
    "os.makedirs(target_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save individual images into these directories\n",
    "# You can use the imwrite function to save images. The ? command will pull up the docstring\n",
    "?imwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO###\n",
    "\n",
    "# Put the pairs of input and target images into the `source_dir` and `target_dir`, respectively.\n",
    "# The goal here is to the train a network for 1 us scan time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 2.3:</h4>\n",
    "    <p>\n",
    "    Now that you arranged the training data we can now create the raw data object.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###TODO###\n",
    "raw_data = RawData.from_folder (\n",
    "    basepath    = 'data/SEM/train',\n",
    "    source_dirs = [''], # fill in your directory for source images\n",
    "    target_dir  = '', # fill in your directory of target images\n",
    "    axes        = '', # what should the axes tag be?\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We generate 2D patches. If you'd like, you can play around with the parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, XY_axes = create_patches(\n",
    "    raw_data = raw_data,\n",
    "    patch_size = (256,256),\n",
    "    n_patches_per_image = 512,\n",
    "    save_file = \"data/SEM/my_1us_training_data.npz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape == Y.shape\n",
    "print(\"shape of X,Y =\", X.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show\n",
    "\n",
    "Let's look at some of the generated patch pairs. (odd rows: _source_, even rows: _target_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    sl = slice(8*i, 8*(i+1)), 0\n",
    "    plot_some(X[sl],Y[sl],title_list=[np.arange(sl[0].start,sl[0].stop)], cmap=\"gray_r\")\n",
    "    plt.show()\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Part 2: Training the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training data\n",
    "\n",
    "Load the patches generated in part 1, use 10% as validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y), (X_val,Y_val), axes = load_training_data('data/SEM/my_1us_training_data.npz', validation_split=0.1, verbose=True)\n",
    "\n",
    "c = axes_dict(axes)['C']\n",
    "n_channel_in, n_channel_out = X.shape[c], Y.shape[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plot_some(X_val[:5],Y_val[:5], cmap = \"gray_r\", pmin=.2,pmax=99.8)\n",
    "plt.suptitle('5 example validation patches (top row: source, bottom row: target)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(axes, n_channel_in, n_channel_out, train_steps_per_epoch=10, train_epochs=100)\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a CARE model with the chosen configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CARE(config, 'my_N2N_model', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model will likely take some time. We recommend to monitor the progress with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard), which allows you to inspect the losses during training.\n",
    "Furthermore, you can look at the predictions for some of the validation images, which can be helpful to recognize problems early on.\n",
    "\n",
    "Start tensorboard as you did in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.train(X,Y, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot final training history (available in TensorBoard during training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss'],['mse','val_mse','mae','val_mae']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Example results for validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "_P = model.keras_model.predict(X_val[:5])\n",
    "if config.probabilistic:\n",
    "    _P = _P[...,:(_P.shape[-1]//2)]\n",
    "plot_some(X_val[:5], Y_val[:5], _P, pmin=.2, pmax=99.8, cmap=\"gray_r\")\n",
    "plt.suptitle('5 example validation patches\\n'      \n",
    "             'top row: input (source),  '          \n",
    "             'mid row: target (ground truth),  '\n",
    "             'bottom row: predicted from source,   '\n",
    "            );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Part 3: Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CARE model\n",
    "\n",
    "Load trained model (located in base directory `models` with name `my_model`) from disk.  \n",
    "The configuration was saved during training and is automatically loaded when `CARE` is initialized with `config=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config=None, name='my_N2N_model', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply CARE network to raw image\n",
    "Now use the trained model to denoise some test images. Let's load the whole tiff stack first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_data = \"data/SEM/test/test.tif\"\n",
    "test_imgs = imread(path_test_data)\n",
    "axes = \"YX\"\n",
    "\n",
    "# separate out the high SNR image as before\n",
    "x_test, x_test_highSNR = test_imgs[:-1], test_imgs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 2.4:</h4>\n",
    "    <p>\n",
    "    Write a function that applies the model to one of the images in the tiff stack and has a flag for plotting the noisy image alongside the restored image as well as smaller crops of each.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO###\n",
    "def apply_on_test(predict_model, img_idx, plot=True):\n",
    "    \"\"\"\n",
    "    Apply the given model on the test image at the given index of the tiff stack.\n",
    "    Returns the noisy image, restored image and the scantime.\n",
    "    \"\"\"\n",
    "    # TODO: insert your code for prediction here\n",
    "    if plot:\n",
    "        # TODO: insert your code to visualize the result here\n",
    "        pass\n",
    "    return img, restored, scantime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function you just wrote to restore one of the images with 1us scan time.\n",
    "noisy_img, restored_img, scantime = apply_on_test(model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ssi_input = structural_similarity(noisy_img, x_test_highSNR, data_range = 65535)\n",
    "ssi_restored = structural_similarity(restored_img, x_test_highSNR, data_range = 65535)\n",
    "print(f\"Structural similarity index (higher is better) wrt average of 4x5us images: \\n\"\n",
    "      f\"Input: {ssi_input} \\n\"\n",
    "      f\"Prediction: {ssi_restored}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_input = peak_signal_noise_ratio(noisy_img, x_test_highSNR, data_range=65535)\n",
    "psnr_restored = peak_signal_noise_ratio(restored_img, x_test_highSNR, data_range=65535)\n",
    "print(f\"Peak signal-to-noise ratio wrt average of 4x5us images:\\n\"\n",
    "      f\"Input: {psnr_input} \\n\"\n",
    "      f\"Prediction: {psnr_restored}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-info\"><h4>\n",
    "    TASK 2.5:</h4>\n",
    "    <p>\n",
    "    Be creative!\n",
    "\n",
    "Can you improve the results by using the data differently or by tweaking the settings?\n",
    "\n",
    "How could you train a single network to process all scan times?\n",
    "    </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<hr style=\"height:2px;\">\n",
    "<div class=\"alert alert-block alert-success\"><h1>\n",
    "    Congratulations!</h1>\n",
    "    <p>\n",
    "    <b>You have reached the second checkpoint of this exercise! Please mark your progress on slack!</b>\n",
    "    </p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:care] *",
   "language": "python",
   "name": "conda-env-care-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
