{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "290f929e",
   "metadata": {},
   "source": [
    "# denoiSplit: joint splitting and unsupervised denoising\n",
    "In this notebook, we tackle the problem of joint splitting and unsupervised denoising, which has a use case in the field of fluorescence microscopy. From a technical perspective, given a noisy image $x$, the goal is to predict two images $c_1$ and $c_2$ such that $x = c_1 + c_2 + n$, where $n$ is the noise in $x$. In other words, we have a superimposed image $x$ and we want to predict the denoised estimates of the constituent images $c_1$ and $c_2$. It is important to note that the network is trained with noisy data and the denoising is done in a unsupervised manner. \n",
    "\n",
    "For this, we will use [denoiSplit](https://arxiv.org/pdf/2403.11854.pdf), a recently developed approach for this task. In this notebook we train denoiSplit and later evaluate it on one validation frame. The overall schema for denoiSplit is shown below:\n",
    "<!-- Insert a figure -->\n",
    "<!-- ![Schema](imgs/teaser.png) -->\n",
    "<img src=\"imgs/teaser.png\" alt=\"drawing\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd72d68",
   "metadata": {},
   "source": [
    "Here, we look at CCPs (clathrin-coated pits) vs ER (Endoplasmic reticulum) task, one of the tasks tackled by denoiSplit which is generated from [BioSR](https://figshare.com/articles/dataset/BioSR/13264793) dataset.\n",
    "\n",
    "1) First, we will load both CCPs and ER images. <br>\n",
    "2) We'll add synthetic Poisson and Gaussian noise to them. This simulates the noise that typically occurs in light microscopy.<br>\n",
    "3) Each noisy CCPs image will be added to each corresponding ER image, making a superimposed image, $x$. <br>\n",
    "4) A VSE network will be trained to take $x$ as input and return unsplit, denoised CCPs and ER images.\n",
    "5) You'll inspect the results, then re-run the notebook with different noise levels and model hyper-parameters to see how performance changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bedf584",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "Set your python kernel to <code>05_image_restoration</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76107363",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Set directories \n",
    "In the next cell, we enumerate the necessary fields for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dbd8fb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "work_dir = \".\"\n",
    "tensorboard_log_dir = os.path.join(work_dir, \"tensorboard_logs\")\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e96ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./denoisplit')\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from denoisplit.data_loader.vanilla_dloader import MultiChDloader\n",
    "from denoisplit.analysis.plot_utils import clean_ax\n",
    "from denoisplit.configs.biosr_config import get_config\n",
    "from denoisplit.training import create_dataset\n",
    "from denoisplit.nets.model_utils import create_model\n",
    "from denoisplit.core.metric_monitor import MetricMonitor\n",
    "from denoisplit.scripts.run import get_mean_std_dict_for_model\n",
    "from denoisplit.core.data_split_type import DataSplitType\n",
    "from denoisplit.scripts.evaluate import get_highsnr_data\n",
    "from denoisplit.analysis.mmse_prediction import get_dset_predictions\n",
    "from denoisplit.data_loader.patch_index_manager import GridAlignement\n",
    "from denoisplit.scripts.evaluate import avg_range_inv_psnr, compute_multiscale_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b18b2",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "<a id='things-to-try'></a>\n",
    "<div class=\"alert alert-block alert-warning\"><h3>\n",
    "    Several Things to try:</h3> \n",
    "    <ol>\n",
    "        <li>Run once with unchanged config to see the performance. </li>\n",
    "        <li>Increase the noise (double the gaussian noise?) and see how performance degrades.</li>\n",
    "        <ol style=\"text-indent: 25px;\">\n",
    "        <li>Recap: Poisson and Gaussian are the two most prominant pixelwise independent noise sources. Here, we encorporate both.  Note that the larger the noise, the harder the task becomes.</li> \n",
    "        </ol>\n",
    "        <li> Increase the max_epochs, if you want to get better performance. </li>\n",
    "        <li> For faster training ( but compromising on performance), reduce the number of hierarchy levels and/or the channel count by modifying <em>config.model.z_dims</em>.</li> \n",
    "        <li> First we train the model to split CCPs and ER channels. Later you can try to split other channels, e.g. F-actin and ER. You'll be able to see that this is a substantially harder task. </li>\n",
    "    </ol>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a6142",
   "metadata": {},
   "source": [
    "## Config "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5e742",
   "metadata": {},
   "source": [
    "Here we'll load the data and set model hyper-parameters.\n",
    "To create the dataset, we'll load two sets of images: CCPs (clathrin-coated pits) and ER (Endoplasmic reticulum). \n",
    "Each image from the CCPs will be added to an image from ER, then noise added on top.\n",
    "\n",
    "The level of noise is determined by `config.data.poisson_noise_factor` and `config.data.synthetic_gaussian_scale`.\n",
    "The former simulates photon shot noise, which is more destructive on lower intensity signals.\n",
    "The latter simulates electronic read noise, which has a constant variance for all signal intensities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04735f11",
   "metadata": {},
   "source": [
    "`config.data.poisson_noise_factor` (float): the intensity of the Poisson (shot) noise.\n",
    "\n",
    "`config.data.synthetic_gaussian_scale` (float): the intensity of the Gaussian (readout) noise.\n",
    "\n",
    "`config.model.z_dims` (list(int)): Determines the depth of our network. The number of entries is the number of levels. The value of each entry is the number of hidden dimensions at each level.\n",
    "\n",
    "`config.training.lr` (float): The learning rate.\n",
    "\n",
    "`config.training.max_epochs` (int): Number of training epochs. Increase for better performance, decrease for shorter training time.\n",
    "\n",
    "`config.training.batch_size` (int): Training batch size. Increasing this will require more memory. Performance may improve, but bigger batches aren't always better.\n",
    "\n",
    "`config.training.num_workers` (int): Number of subprocesses to use for data loading. This is different for different GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca8dc2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "datapath = \"./../data/\"\n",
    "\n",
    "# load the default config.\n",
    "config = get_config()\n",
    "\n",
    "config.data.ch1_fname = 'ER/GT_all.mrc'\n",
    "config.data.ch2_fname = 'CCPs/GT_all.mrc'\n",
    "# Channge the noise level\n",
    "config.data.poisson_noise_factor = (\n",
    "    1000  # 1000 is the default value. noise increases with the value.\n",
    ")\n",
    "config.data.synthetic_gaussian_scale = (\n",
    "    5000  # 5000 is the default value. noise increases with the value.\n",
    ")\n",
    "\n",
    "# change the number of hierarchy levels.\n",
    "config.model.z_dims = [128, 128, 128, 128]\n",
    "\n",
    "# change the training parameters\n",
    "config.training.lr = 3e-3\n",
    "config.training.max_epochs = 10\n",
    "config.training.batch_size = 8\n",
    "config.training.num_workers = 4\n",
    "\n",
    "config.workdir = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83242ab",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Create the dataset and pytorch dataloaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3cd66",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "train_dset = MultiChDloader(config.data,\n",
    "                            datapath,\n",
    "                            datasplit_type=DataSplitType.Train,\n",
    "                            val_fraction=config.training.val_fraction,\n",
    "                            test_fraction=config.training.test_fraction,\n",
    "                            normalized_input=config.data.normalized_input,\n",
    "                            use_one_mu_std=config.data.use_one_mu_std,\n",
    "                            enable_rotation_aug=config.data.train_aug_rotate\n",
    "                            )\n",
    "val_dset = MultiChDloader(config.data,\n",
    "                datapath,\n",
    "                datasplit_type=DataSplitType.Val,\n",
    "                val_fraction=config.training.val_fraction,\n",
    "                test_fraction=config.training.test_fraction,\n",
    "                normalized_input=config.data.normalized_input,\n",
    "                use_one_mu_std=config.data.use_one_mu_std,\n",
    "                enable_rotation_aug=False,  # No rotation aug on validation\n",
    "                max_val=train_dset.get_max_val(),\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b47e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dict, std_dict = train_dset.compute_mean_std()\n",
    "train_dset.set_mean_std(mean_dict, std_dict)\n",
    "val_dset.set_mean_std(mean_dict, std_dict)\n",
    "\n",
    "mean_dict, std_dict = get_mean_std_dict_for_model(config, train_dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28072b04",
   "metadata": {},
   "source": [
    "## Inspecting the training data generated using the above config.\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "If you want to change the noise, then you should change the config first and run the following cell again to see how the training data changes in terms of noise.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d6ef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dset.set_img_sz(800, 64)\n",
    "inp, tar = val_dset[0]\n",
    "_,ax = plt.subplots(1,3, figsize=(15,5))\n",
    "ax[0].imshow(inp[0], cmap='magma')\n",
    "ax[0].set_title('Input')\n",
    "ax[1].imshow(tar[0], cmap='magma')\n",
    "ax[1].set_title('Channel 1')\n",
    "ax[2].imshow(tar[1], cmap='magma')\n",
    "ax[2].set_title('Channel 2')\n",
    "\n",
    "val_dset.set_img_sz(config.data.image_size, config.data.image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b959db",
   "metadata": {},
   "source": [
    "## Define the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09035708",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "batch_size = config.training.batch_size\n",
    "train_dloader = DataLoader(\n",
    "    train_dset,\n",
    "    pin_memory=False,\n",
    "    num_workers=config.training.num_workers,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    pin_memory=False,\n",
    "    num_workers=config.training.num_workers,\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc243f",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Create the model.\n",
    "Here, we instantiate the [denoiSplit model](https://arxiv.org/pdf/2403.11854.pdf). For simplicity, we have disabled the noise model. For enabling the noise model, one would additionally have to train a denoiser. The next step would be to create a noise model using the noisy data and the corresponding denoised predictions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec5ec5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model = create_model(config, mean_dict, std_dict)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cde1e7",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e538b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(tensorboard_log_dir, name=\"\", version=\"\", default_hp_metric=False)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=config.training.max_epochs,\n",
    "    gradient_clip_val=(\n",
    "        None\n",
    "        if not model.automatic_optimization\n",
    "        else config.training.grad_clip_norm_value\n",
    "    ),\n",
    "    logger=logger,\n",
    "    precision=config.training.precision,\n",
    ")\n",
    "trainer.fit(model, train_dloader, val_dloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c06421e",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca722a9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_ = model.cuda()\n",
    "eval_frame_idx = 0\n",
    "# reducing the data, just for speed\n",
    "val_dset.reduce_data(t_list=[eval_frame_idx])\n",
    "mmse_count = 10\n",
    "overlapping_padding_kwargs = {\n",
    "    \"mode\": config.data.get(\"padding_mode\", \"constant\"),\n",
    "}\n",
    "if overlapping_padding_kwargs[\"mode\"] == \"constant\":\n",
    "    overlapping_padding_kwargs[\"constant_values\"] = config.data.get(\"padding_value\", 0)\n",
    "val_dset.set_img_sz(\n",
    "    128,\n",
    "    32,\n",
    "    grid_alignment=GridAlignement.Center,\n",
    "    overlapping_padding_kwargs=overlapping_padding_kwargs,\n",
    ")\n",
    "\n",
    "# MMSE prediction\n",
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = (\n",
    "    get_dset_predictions(\n",
    "        model,\n",
    "        val_dset,\n",
    "        batch_size,\n",
    "        num_workers=config.training.num_workers,\n",
    "        mmse_count=mmse_count,\n",
    "        model_type=config.model.model_type,\n",
    "    )\n",
    ")\n",
    "\n",
    "# One sample prediction\n",
    "pred1_tiled, *_ = get_dset_predictions(\n",
    "    model,\n",
    "    val_dset,\n",
    "    batch_size,\n",
    "    num_workers=config.training.num_workers,\n",
    "    mmse_count=1,\n",
    "    model_type=config.model.model_type,\n",
    ")\n",
    "# One sample prediction\n",
    "pred2_tiled, *_ = get_dset_predictions(\n",
    "    model,\n",
    "    val_dset,\n",
    "    batch_size,\n",
    "    num_workers=config.training.num_workers,\n",
    "    mmse_count=1,\n",
    "    model_type=config.model.model_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c9bd5b",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Stitching predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df4c25",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from denoisplit.analysis.stitch_prediction import stitch_predictions\n",
    "\n",
    "pred = stitch_predictions(pred_tiled, val_dset)\n",
    "\n",
    "\n",
    "# ignore pixels at the [right/bottom] boundary.\n",
    "def print_ignored_pixels():\n",
    "    ignored_pixels = 1\n",
    "    while (\n",
    "        pred[\n",
    "            0,\n",
    "            -ignored_pixels:,\n",
    "            -ignored_pixels:,\n",
    "        ].std()\n",
    "        == 0\n",
    "    ):\n",
    "        ignored_pixels += 1\n",
    "    ignored_pixels -= 1\n",
    "    return ignored_pixels\n",
    "\n",
    "\n",
    "actual_ignored_pixels = print_ignored_pixels()\n",
    "pred = pred[:, :-actual_ignored_pixels, :-actual_ignored_pixels]\n",
    "pred1 = stitch_predictions(pred1_tiled, val_dset)[\n",
    "    :, :-actual_ignored_pixels, :-actual_ignored_pixels\n",
    "]\n",
    "pred2 = stitch_predictions(pred2_tiled, val_dset)[\n",
    "    :, :-actual_ignored_pixels, :-actual_ignored_pixels\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f451a4e1",
   "metadata": {},
   "source": [
    "## Get the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0866ed",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "highres_data = get_highsnr_data(config, datapath, DataSplitType.Val)\n",
    "\n",
    "highres_data = highres_data[\n",
    "    eval_frame_idx : eval_frame_idx + 1,\n",
    "    :-actual_ignored_pixels,\n",
    "    :-actual_ignored_pixels,\n",
    "]\n",
    "\n",
    "noisy_data = val_dset._noise_data[..., 1:] + val_dset._data\n",
    "noisy_data = noisy_data[..., :-actual_ignored_pixels, :-actual_ignored_pixels, :]\n",
    "model_input = np.mean(noisy_data, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0a5837",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\"><h1>Checkpoint 1: Model trained</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a0b75",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# Qualitative performance on a random crop\n",
    "denoiSplit is capable of sampling from a learned posterior.\n",
    "Here we show full input frame and a randomly cropped input (300*300),\n",
    "two corresponding prediction samples, the difference between the two samples (S1−S2),\n",
    "the MMSE prediction, and otherwise unused high SNR microscopy crop. \n",
    "The MMSE predictions are computed by averaging 10 samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29754975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_str(ax_, txt):\n",
    "    \"\"\"\n",
    "    Add psnr string to the axes\n",
    "    \"\"\"\n",
    "    textstr = txt\n",
    "    props = dict(boxstyle=\"round\", facecolor=\"gray\", alpha=0.5)\n",
    "    # place a text box in upper left in axes coords\n",
    "    ax_.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        textstr,\n",
    "        transform=ax_.transAxes,\n",
    "        fontsize=11,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=props,\n",
    "        color=\"white\",\n",
    "    )\n",
    "\n",
    "\n",
    "ncols = 7\n",
    "nrows = 2\n",
    "sz = 300\n",
    "hs = np.random.randint(0, highres_data.shape[1] - sz)\n",
    "ws = np.random.randint(0, highres_data.shape[2] - sz)\n",
    "_, ax = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4))\n",
    "ax[0, 0].imshow(model_input[0], cmap=\"magma\")\n",
    "\n",
    "rect = patches.Rectangle((ws, hs), sz, sz, linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
    "ax[0, 0].add_patch(rect)\n",
    "ax[1, 0].imshow(model_input[0, hs : hs + sz, ws : ws + sz], cmap=\"magma\")\n",
    "add_str(ax[0, 0], \"Full Input Frame\")\n",
    "add_str(ax[1, 0], \"Random Input Crop\")\n",
    "\n",
    "ax[0, 1].imshow(noisy_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 1].imshow(noisy_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "ax[0, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "ax[0, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "diff = pred2 - pred1\n",
    "ax[0, 4].imshow(diff[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"coolwarm\")\n",
    "ax[1, 4].imshow(diff[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"coolwarm\")\n",
    "\n",
    "ax[0, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "\n",
    "ax[0, 6].imshow(highres_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "ax[1, 6].imshow(highres_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "ax[0, 0].set_title(\"Model Input\", size=13)\n",
    "ax[0, 1].set_title(\"Target\", size=13)\n",
    "ax[0, 2].set_title(\"Sample 1 (S1)\", size=13)\n",
    "ax[0, 3].set_title(\"Sample 2 (S2)\", size=13)\n",
    "ax[0, 4].set_title('\"S2\" - \"S1\"', size=13)\n",
    "ax[0, 5].set_title(f\"Prediction MMSE({mmse_count})\", size=13)\n",
    "ax[0, 6].set_title(\"High SNR Reality\", size=13)\n",
    "\n",
    "twinx = ax[0, 6].twinx()\n",
    "twinx.set_ylabel(\"Channel 1\", size=13)\n",
    "clean_ax(twinx)\n",
    "twinx = ax[1, 6].twinx()\n",
    "twinx.set_ylabel(\"Channel 2\", size=13)\n",
    "clean_ax(twinx)\n",
    "clean_ax(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ce25bb",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "# Qualitative performance on multiple random crops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1e50d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "nimgs = 3\n",
    "ncols = 7\n",
    "nrows = 2 * nimgs\n",
    "sz = 300\n",
    "_, ax = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4))\n",
    "\n",
    "for img_idx in range(nimgs):\n",
    "    hs = np.random.randint(0, highres_data.shape[1] - sz)\n",
    "    ws = np.random.randint(0, highres_data.shape[2] - sz)\n",
    "    ax[2 * img_idx, 0].imshow(model_input[0], cmap=\"magma\")\n",
    "\n",
    "    rect = patches.Rectangle(\n",
    "        (ws, hs), sz, sz, linewidth=1, edgecolor=\"r\", facecolor=\"none\"\n",
    "    )\n",
    "    ax[2 * img_idx, 0].add_patch(rect)\n",
    "    ax[2 * img_idx + 1, 0].imshow(\n",
    "        model_input[0, hs : hs + sz, ws : ws + sz], cmap=\"magma\"\n",
    "    )\n",
    "    add_str(ax[2 * img_idx, 0], \"Full Input Frame\")\n",
    "    add_str(ax[2 * img_idx + 1, 0], \"Random Input Crop\")\n",
    "\n",
    "    ax[2 * img_idx, 1].imshow(\n",
    "        noisy_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\"\n",
    "    )\n",
    "    ax[2 * img_idx + 1, 1].imshow(\n",
    "        noisy_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\"\n",
    "    )\n",
    "\n",
    "    ax[2 * img_idx, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "    ax[2 * img_idx + 1, 2].imshow(pred1[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "    ax[2 * img_idx, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "    ax[2 * img_idx + 1, 3].imshow(pred2[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "    diff = pred2 - pred1\n",
    "    ax[2 * img_idx, 4].imshow(diff[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"coolwarm\")\n",
    "    ax[2 * img_idx + 1, 4].imshow(\n",
    "        diff[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"coolwarm\"\n",
    "    )\n",
    "\n",
    "    ax[2 * img_idx, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\")\n",
    "    ax[2 * img_idx + 1, 5].imshow(pred[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\")\n",
    "\n",
    "    ax[2 * img_idx, 6].imshow(\n",
    "        highres_data[0, hs : hs + sz, ws : ws + sz, 0], cmap=\"magma\"\n",
    "    )\n",
    "    ax[2 * img_idx + 1, 6].imshow(\n",
    "        highres_data[0, hs : hs + sz, ws : ws + sz, 1], cmap=\"magma\"\n",
    "    )\n",
    "\n",
    "    twinx = ax[2 * img_idx, 6].twinx()\n",
    "    twinx.set_ylabel(\"Channel 1\", size=15)\n",
    "    clean_ax(twinx)\n",
    "\n",
    "    twinx = ax[2 * img_idx + 1, 6].twinx()\n",
    "    twinx.set_ylabel(\"Channel 2\", size=15)\n",
    "    clean_ax(twinx)\n",
    "\n",
    "ax[0, 0].set_title(\"Model Input\", size=15)\n",
    "ax[0, 1].set_title(\"Target\", size=15)\n",
    "ax[0, 2].set_title(\"Sample 1 (S1)\", size=15)\n",
    "ax[0, 3].set_title(\"Sample 2 (S2)\", size=15)\n",
    "ax[0, 4].set_title('\"S2\" - \"S1\"', size=15)\n",
    "ax[0, 5].set_title(f\"Prediction MMSE({mmse_count})\", size=15)\n",
    "ax[0, 6].set_title(\"High SNR Reality\", size=15)\n",
    "\n",
    "clean_ax(ax)\n",
    "plt.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2fe0b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <h3>Questions:</h3>\n",
    "    1) When is it relatively easy to split the two structures from the input?<br>\n",
    "    2) Why might you see the grid-like artifacts and what can be done to mitigate this?<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ea88e",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Quantitative performance\n",
    "We evaluate on two metrics, Multiscale SSIM and PSNR.\n",
    "\n",
    "Multi-scale SSIM is a metric that computes SSIM at multiple scales and averages them. It's reminiscent of multiscale processing in the early vision system \n",
    "\n",
    "PSNR is a metric that computes the peak signal-to-noise ratio. It's one of the most widely used metrics to measure the quality of image reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3246db",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tar = mean_dict[\"target\"].cpu().numpy().squeeze().reshape(1, 1, 1, 2)\n",
    "std_tar = std_dict[\"target\"].cpu().numpy().squeeze().reshape(1, 1, 1, 2)\n",
    "pred_unnorm = pred * std_tar + mean_tar\n",
    "\n",
    "psnr_list = [\n",
    "    avg_range_inv_psnr(highres_data[..., i].copy(), pred_unnorm[..., i].copy())\n",
    "    for i in range(highres_data.shape[-1])\n",
    "]\n",
    "ssim_list = compute_multiscale_ssim(highres_data.copy(), pred_unnorm.copy())\n",
    "print(\"Metric: Ch1\\t Ch2\")\n",
    "print(f\"PSNR  : {psnr_list[0]:.2f}\\t {psnr_list[1]:.2f}\")\n",
    "print(f\"MS-SSIM  : {ssim_list[0]:.3f}\\t {ssim_list[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bdbbe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><h1>Checkpoint 2: Try one of the \"Several things to try\"</h1>\n",
    "\n",
    "</div>\n",
    "\n",
    "Click [here](#things-to-try) to go back to the relevant section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd91211",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\"><div class=\"alert alert-block alert-success\"><h1>End of the exercise</h1>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "05_image_restoration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
