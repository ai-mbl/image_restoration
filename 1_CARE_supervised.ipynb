{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Train your first CARE network (supervised)\n",
    "\n",
    "In this first example we will train a CARE network for a 3D denoising task, where corresponding pairs of low and high quality stacks can be acquired.\n",
    "\n",
    "Each pair should be registered, which is best achieved by acquiring both stacks _interleaved_, i.e. as different channels that correspond to the different exposure/laser settings. \n",
    "\n",
    "We will use a single Tribolium stack pair for training, whereas in your real-life application you should aim to acquire at least 10-50 stacks from different developmental timepoints to ensure a well trained model. \n",
    "\n",
    "By the way, this exercise was adapted from the examples in the  [CSB Deep Repo](https://github.com/CSBDeep/CSBDeep) (as you see we will also use that library extensively here).\n",
    "More documentation is available at http://csbdeep.bioimagecomputing.com/doc/.\n",
    "\n",
    "There will be no tasks to fill in in this exercise, but go through each cell and try to understand what's going on - it will help you in the next part! We put some questions to answer along the way to help with that.\n",
    "\n",
    "You'll want to select the kernel for the `'care'` environment for this exercise.\n",
    "![title](nb_material/change_kernel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "%matplotlib inline\n",
    "%load_ext tensorboard\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import axes_dict, download_and_extract_zip_file, Path, plot_history, plot_some\n",
    "from csbdeep.utils.tf import limit_gpu_memory\n",
    "from csbdeep.data import RawData, create_patches\n",
    "from csbdeep.io import load_training_data, save_tiff_imagej_compatible\n",
    "from csbdeep.models import Config, CARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Part 1: Training Data Generation\n",
    "Network training usually happens on batches of smaller sized images than the ones recorded on a microscopy. In this first part of the exercise, we will load all of the image data and chop it into smaller pieces, a.k.a. patches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download example data\n",
    "\n",
    "First we download some example data, consisting of low-SNR and high-SNR 3D images of Tribolium.  \n",
    "Note that `GT` stands for ground truth and represents high signal-to-noise ratio (SNR) stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_and_extract_zip_file (\n",
    "    url       = 'http://csbdeep.bioimagecomputing.com/example_data/tribolium.zip',\n",
    "    targetdir = 'data',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the training stack pair via maximum-projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = imread('data/tribolium/train/GT/nGFP_0.1_0.2_0.5_20_13_late.tif')\n",
    "x_train = imread('data/tribolium/train/low/nGFP_0.1_0.2_0.5_20_13_late.tif')\n",
    "print('image size =', x_train.shape)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plot_some(np.stack([x_train,y_train]),\n",
    "          title_list=[['low (maximum projection)','GT (maximum projection)']], \n",
    "          pmin=2,pmax=99.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training data for CARE\n",
    "\n",
    "We first need to create a `RawData` object, which defines how to get the pairs of low/high SNR stacks and the semantics of each axis (e.g. which one is considered a color channel, etc.).\n",
    "\n",
    "Here we have two folders \"low\" and \"GT\", where corresponding low and high-SNR stacks are TIFF images with identical filenames.  \n",
    "For this case, we can simply use `RawData.from_folder` and set `axes = 'ZYX'` to indicate the semantic order of the image axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = RawData.from_folder (\n",
    "    basepath    = 'data/tribolium/train',\n",
    "    source_dirs = ['low'],\n",
    "    target_dir  = 'GT',\n",
    "    axes        = 'ZYX',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From corresponding stacks, we now generate some 3D patches. As a general rule, use a patch size that is a power of two along XYZT, or at least divisible by 8.  \n",
    "Typically, you should use more patches the more trainings stacks you have. By default, patches are sampled from non-background regions (i.e. that are above a relative threshold), see the documentation of `create_patches` for details.\n",
    "\n",
    "Note that returned values `(X, Y, XY_axes)` by `create_patches` are not to be confused with the image axes X and Y.  \n",
    "By convention, the variable name `X` (or `x`) refers to an input variable for a machine learning model, whereas `Y` (or `y`) indicates an output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, XY_axes = create_patches (\n",
    "    raw_data            = raw_data,\n",
    "    patch_size          = (16,64,64),\n",
    "    n_patches_per_image = 1024,\n",
    "    save_file           = 'data/tribolium/my_training_data.npz',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape == Y.shape\n",
    "print(\"shape of X,Y =\", X.shape)\n",
    "print(\"axes  of X,Y =\", XY_axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show\n",
    "\n",
    "This shows the maximum projection of some of the generated patch pairs (odd rows: *source*, even rows: *target*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    sl = slice(8*i, 8*(i+1)), 0\n",
    "    plot_some(X[sl],Y[sl],title_list=[np.arange(sl[0].start,sl[0].stop)])\n",
    "    plt.show()\n",
    "None;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "1. Where is the training data located? \n",
    "2.How does data have to be stored so that CSBDeep will find and load it correctly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Part 2: Training the network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training data\n",
    "\n",
    "Load the patches generated in part 1, use 10% as validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y), (X_val,Y_val), axes = load_training_data('data/tribolium/my_training_data.npz', validation_split=0.1, verbose=True)\n",
    "\n",
    "c = axes_dict(axes)['C']\n",
    "n_channel_in, n_channel_out = X.shape[c], Y.shape[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plot_some(X_val[:5],Y_val[:5])\n",
    "plt.suptitle('5 example validation patches (top row: source, bottom row: target)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the CARE model\n",
    "Before we construct the actual CARE model, we have to define its configuration via a `Config` object, which includes \n",
    "* parameters of the underlying neural network,\n",
    "* the learning rate,\n",
    "* the number of parameter updates per epoch,\n",
    "* the loss function, and\n",
    "* whether the model is probabilistic or not.\n",
    "\n",
    "The defaults should be sensible in many cases, so a change should only be necessary if the training process fails.  \n",
    "\n",
    "<span style=\"color:red;font-weight:bold;\">Important</span>: Note that for this notebook we use a very small number of update steps per epoch for immediate feedback, whereas this number should be increased considerably (e.g. `train_steps_per_epoch=400`) to obtain a well-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(axes, n_channel_in, n_channel_out, train_steps_per_epoch=10, train_epochs=100)\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a CARE model with the chosen configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CARE(config, 'my_CARE_model', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model will likely take some time. We recommend to monitor the progress with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard), which allows you to inspect the losses during training.\n",
    "Furthermore, you can look at the predictions for some of the validation images, which can be helpful to recognize problems early on.\n",
    "\n",
    "We start tensorboard in the notebook (you can also launch it outside the notebook if you prefer by changing the `%` to `!`) to then monitor the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir models/my_CARE_model --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.train(X,Y, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot final training history (available in TensorBoard during training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss'],['mse','val_mse','mae','val_mae']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Example results for validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "_P = model.keras_model.predict(X_val[:5])\n",
    "if config.probabilistic:\n",
    "    _P = _P[...,:(_P.shape[-1]//2)]\n",
    "plot_some(X_val[:5],Y_val[:5],_P,pmax=99.5)\n",
    "plt.suptitle('5 example validation patches\\n'      \n",
    "             'top row: input (source),  '          \n",
    "             'middle row: target (ground truth),  '\n",
    "             'bottom row: predicted from source');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "1. Where are trained models stored? What models are being stored, how do they differ?\n",
    "2. How does the name of the saved models get specified?\n",
    "3. How can you influence the number of training steps per epoch? What did you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "## Part 3: Prediction\n",
    "\n",
    "Plot the test stack pair and define its image axes, which will be needed later for CARE prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test = imread('data/tribolium/test/GT/nGFP_0.1_0.2_0.5_20_14_late.tif')\n",
    "x_test = imread('data/tribolium/test/low/nGFP_0.1_0.2_0.5_20_14_late.tif')\n",
    "\n",
    "axes = 'ZYX'\n",
    "print('image size =', x_test.shape)\n",
    "print('image axes =', axes)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "plot_some(np.stack([x_test,y_test]),\n",
    "          title_list=[['low (maximum projection)','GT (maximum projection)']], \n",
    "          pmin=2,pmax=99.8);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CARE model\n",
    "\n",
    "Load trained model (located in base directory `models` with name `my_model`) from disk.  \n",
    "The configuration was saved during training and is automatically loaded when `CARE` is initialized with `config=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config=None, name='my_CARE_model', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply CARE network to raw image\n",
    "Predict the restored image (image will be successively split into smaller tiles if there are memory issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "restored = model.predict(x_test, axes, n_tiles=(1,2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save restored image\n",
    "\n",
    "Save the restored image stack as a ImageJ-compatible TIFF image, i.e. the image can be opened in ImageJ/Fiji with correct axes semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Path('results').mkdir(exist_ok=True)\n",
    "save_tiff_imagej_compatible('results/%s_nGFP_0.1_0.2_0.5_20_14_late.tif' % model.name, restored, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results\n",
    "Plot the test stack pair and the predicted restored stack (middle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plot_some(np.stack([x_test,restored,y_test]),\n",
    "          title_list=[['low (maximum projection)','CARE (maximum projection)','GT (maximum projection)']], \n",
    "          pmin=2,pmax=99.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\">\n",
    "\n",
    "### Bonus Questions:\n",
    "Feel free to skip these\n",
    "1. How would you load an existing CARE network and continue to train it? (This is _not_ done in this notebook)\n",
    "2. How would you go about saving the new model separately, under a new name?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "# Congratulations!\n",
    "__You have reached the first checkpoint of this exercise! Please mark your progress on slack and move on to the next part!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:care]",
   "language": "python",
   "name": "conda-env-care-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
